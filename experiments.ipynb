{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'CORD19_GraphOfDocs/datasets'\n",
    "datasets = [\n",
    "    [f'{path}/dataset1/train_687.csv', f'{path}/dataset1/test_849.csv'],\n",
    "    [f'{path}/dataset2/train_878.csv', f'{path}/dataset2/test_1573.csv'],\n",
    "    [f'{path}/dataset3/train_1761.csv', f'{path}/dataset3/test_2662.csv'],\n",
    "    [f'{path}/dataset4/train_3425.csv', f'{path}/dataset4/test_7869.csv'],\n",
    "    [f'{path}/dataset5/train_5165.csv', f'{path}/dataset5/test_13107.csv'],\n",
    "    [f'{path}/dataset6/train_5415.csv', f'{path}/dataset6/test_16434.csv'],\n",
    "    [f'{path}/dataset7/train_6347.csv', f'{path}/dataset7/test_26144.csv'],\n",
    "    [f'{path}/dataset8/train_8745.csv', f'{path}/dataset8/test_34965.csv'],\n",
    "    [f'{path}/dataset9/train_13276.csv', f'{path}/dataset9/test_49747.csv']\n",
    "]\n",
    "\n",
    "features_combinations = [\n",
    "    ['adamic_adar', 'common_neighbors', 'preferential_attachment', 'total_neighbors'],\n",
    "    ['adamic_adar', 'common_neighbors', 'preferential_attachment', 'total_neighbors', 'similarity'],\n",
    "    ['adamic_adar', 'similarity'],\n",
    "    ['adamic_adar'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    return LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "\n",
    "def knn():\n",
    "    return KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "def linear_svm():\n",
    "    return LinearSVC()\n",
    "\n",
    "def decision_tree():\n",
    "    return DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "\n",
    "def get_normalizer():\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def calculate_scores(classifier, selected_features, train_df, test_df):\n",
    "    normalizer = get_normalizer()\n",
    "    normalizer.fit(train_df[selected_features])\n",
    "    train_data = normalizer.transform(train_df[selected_features])\n",
    "    test_data = normalizer.transform(test_df[selected_features])\n",
    "    classifier.fit(train_data, train_df['label'])\n",
    "    predictions = classifier.predict(test_data)\n",
    "    res = [\n",
    "        accuracy_score(test_df['label'], predictions),\n",
    "        precision_score(test_df['label'], predictions),\n",
    "        recall_score(test_df['label'], predictions)\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "def evaluate_dataset(train_path, test_path, classifier):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    scores = []\n",
    "\n",
    "    for feature_columns in features_combinations: \n",
    "        scores.append([feature_columns, *calculate_scores(classifier(), feature_columns, train_df, test_df)])\n",
    "\n",
    "    return scores\n",
    "\n",
    "def evaluate_datasets(classifier_fun):\n",
    "    print(classifier_fun)\n",
    "    all_scores = []\n",
    "    for index, dataset in enumerate(datasets, 1):\n",
    "        #print(f'dataset {index}', '-'*60)\n",
    "        all_scores.append(evaluate_dataset(dataset[0], dataset[1], classifier_fun))\n",
    "\n",
    "    return generate_statistics(all_scores)\n",
    "\n",
    "def print_scores(scores):\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for features, accuracy, precision, recall,  in scores:\n",
    "        print(features)\n",
    "        print('A:', accuracy, 'P:', precision, 'R:', recall, '\\n')\n",
    "        \n",
    "def print_statistics(statistics, score):\n",
    "    print(score, '-'*10)\n",
    "    statistics = sorted(statistics[score], key=lambda x: x[1], reverse=True)\n",
    "    for row in statistics:\n",
    "        print(f'{row[0]}|AVG:{row[1]:.3f}|MIN:{row[3]:.3f}|MAX:{row[2]:.3f}|STD:{row[4]:.3f}')\n",
    "\n",
    "def generate_statistics(all_scores):\n",
    "    # all_scores dimensions: dataset, feature combination, evaluation score:(1: accuracy, 2: precision, 3:recall)\n",
    "    number_of_datasets = len(datasets)\n",
    "    number_of_features_combinations = len(features_combinations)\n",
    "    \n",
    "    accuracy_scores_per_features_combination = []\n",
    "    for i in range(number_of_features_combinations):\n",
    "        accuracies = []\n",
    "        for j in range(number_of_datasets):\n",
    "            accuracies.append(all_scores[j][i][1])\n",
    "        accuracies = np.array(accuracies)\n",
    "        accuracy_std = np.std(accuracies)\n",
    "        accuracy_max = np.max(accuracies)\n",
    "        accuracy_min = np.min(accuracies)\n",
    "        accuracy_average = np.mean(accuracies)\n",
    "        identifier = '-'.join(features_combinations[i])\n",
    "        accuracy_scores_per_features_combination.append([\n",
    "            identifier,\n",
    "            accuracy_average,\n",
    "            accuracy_max,\n",
    "            accuracy_min,\n",
    "            accuracy_std\n",
    "        ])\n",
    "\n",
    "    precision_scores_per_features_combination = []\n",
    "    for i in range(number_of_features_combinations):\n",
    "        precisions = []\n",
    "        for j in range(number_of_datasets):\n",
    "            precisions.append(all_scores[j][i][2])\n",
    "        precisions = np.array(precisions)\n",
    "        precision_std = np.std(precisions)\n",
    "        precision_max = np.max(precisions)\n",
    "        precision_min = np.min(precisions)\n",
    "        precision_average = np.mean(precisions)\n",
    "        identifier = '-'.join(features_combinations[i])\n",
    "        precision_scores_per_features_combination.append([\n",
    "            identifier,\n",
    "            precision_average,\n",
    "            precision_max,\n",
    "            precision_min,\n",
    "            precision_std\n",
    "        ])\n",
    "    \n",
    "    recall_scores_per_features_combination = []\n",
    "    for i in range(number_of_features_combinations):\n",
    "        recalls = []\n",
    "        for j in range(number_of_datasets):\n",
    "            recalls.append(all_scores[j][i][3])\n",
    "        recalls = np.array(recalls)\n",
    "        recall_std = np.std(recalls)\n",
    "        recall_max = np.max(recalls)\n",
    "        recall_min = np.min(recalls)\n",
    "        recall_average = np.mean(recalls)\n",
    "        identifier = '-'.join(features_combinations[i])\n",
    "        recall_scores_per_features_combination.append([\n",
    "            identifier,\n",
    "            recall_average,\n",
    "            recall_max,\n",
    "            recall_min,\n",
    "            recall_std\n",
    "        ])\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_scores_per_features_combination,\n",
    "        'precision': precision_scores_per_features_combination,\n",
    "        'recall': recall_scores_per_features_combination\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function logistic_regression at 0x7f9b19369ea0>\n",
      "accuracy ----------\n",
      "adamic_adar-similarity|AVG:0.973|MIN:0.967|MAX:0.982|STD:0.005\n",
      "adamic_adar|AVG:0.971|MIN:0.963|MAX:0.979|STD:0.005\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.959|MIN:0.942|MAX:0.968|STD:0.007\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.955|MIN:0.938|MAX:0.964|STD:0.008\n",
      "##########\n",
      "precision ----------\n",
      "adamic_adar-similarity|AVG:0.975|MIN:0.950|MAX:0.991|STD:0.013\n",
      "adamic_adar|AVG:0.968|MIN:0.945|MAX:0.986|STD:0.013\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.961|MIN:0.910|MAX:0.984|STD:0.023\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.955|MIN:0.907|MAX:0.980|STD:0.022\n",
      "##########\n",
      "recall ----------\n",
      "adamic_adar|AVG:0.975|MIN:0.966|MAX:0.986|STD:0.007\n",
      "adamic_adar-similarity|AVG:0.972|MIN:0.957|MAX:0.986|STD:0.008\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.958|MIN:0.941|MAX:0.982|STD:0.013\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.956|MIN:0.937|MAX:0.976|STD:0.012\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "statistics = evaluate_datasets(logistic_regression)\n",
    "\n",
    "print_statistics(statistics, 'accuracy')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'precision')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'recall')\n",
    "print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function knn at 0x7f9add918510>\n",
      "accuracy ----------\n",
      "adamic_adar-similarity|AVG:0.954|MIN:0.914|MAX:0.973|STD:0.017\n",
      "adamic_adar|AVG:0.938|MIN:0.908|MAX:0.960|STD:0.018\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.938|MIN:0.847|MAX:0.974|STD:0.036\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.936|MIN:0.847|MAX:0.973|STD:0.035\n",
      "##########\n",
      "precision ----------\n",
      "adamic_adar-similarity|AVG:0.921|MIN:0.859|MAX:0.956|STD:0.029\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.899|MIN:0.768|MAX:0.960|STD:0.054\n",
      "adamic_adar|AVG:0.897|MIN:0.850|MAX:0.935|STD:0.029\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.896|MIN:0.768|MAX:0.959|STD:0.053\n",
      "##########\n",
      "recall ----------\n",
      "adamic_adar-similarity|AVG:0.995|MIN:0.992|MAX:0.999|STD:0.002\n",
      "adamic_adar|AVG:0.993|MIN:0.989|MAX:0.999|STD:0.003\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.993|MIN:0.990|MAX:0.997|STD:0.002\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.992|MIN:0.990|MAX:0.997|STD:0.002\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "statistics = evaluate_datasets(knn)\n",
    "\n",
    "print_statistics(statistics, 'accuracy')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'precision')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'recall')\n",
    "print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function linear_svm at 0x7f9add918598>\n",
      "accuracy ----------\n",
      "adamic_adar-similarity|AVG:0.972|MIN:0.956|MAX:0.981|STD:0.009\n",
      "adamic_adar|AVG:0.969|MIN:0.954|MAX:0.980|STD:0.009\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.963|MIN:0.936|MAX:0.976|STD:0.012\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.959|MIN:0.933|MAX:0.971|STD:0.012\n",
      "##########\n",
      "precision ----------\n",
      "adamic_adar-similarity|AVG:0.957|MIN:0.925|MAX:0.977|STD:0.017\n",
      "adamic_adar|AVG:0.953|MIN:0.920|MAX:0.976|STD:0.018\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.946|MIN:0.889|MAX:0.976|STD:0.026\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.942|MIN:0.886|MAX:0.972|STD:0.026\n",
      "##########\n",
      "recall ----------\n",
      "adamic_adar-similarity|AVG:0.989|MIN:0.986|MAX:0.994|STD:0.002\n",
      "adamic_adar|AVG:0.987|MIN:0.982|MAX:0.995|STD:0.004\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.983|MIN:0.972|MAX:0.996|STD:0.008\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.979|MIN:0.969|MAX:0.995|STD:0.009\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "statistics = evaluate_datasets(linear_svm)\n",
    "\n",
    "print_statistics(statistics, 'accuracy')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'precision')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'recall')\n",
    "print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function decision_tree at 0x7f9add918730>\n",
      "accuracy ----------\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.930|MIN:0.839|MAX:0.980|STD:0.047\n",
      "adamic_adar-similarity|AVG:0.928|MIN:0.837|MAX:0.972|STD:0.046\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.922|MIN:0.828|MAX:0.979|STD:0.056\n",
      "adamic_adar|AVG:0.880|MIN:0.663|MAX:0.958|STD:0.093\n",
      "##########\n",
      "precision ----------\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.887|MIN:0.759|MAX:0.969|STD:0.071\n",
      "adamic_adar-similarity|AVG:0.885|MIN:0.758|MAX:0.956|STD:0.068\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.878|MIN:0.746|MAX:0.968|STD:0.081\n",
      "adamic_adar|AVG:0.827|MIN:0.600|MAX:0.929|STD:0.107\n",
      "##########\n",
      "recall ----------\n",
      "adamic_adar-similarity|AVG:0.995|MIN:0.991|MAX:0.999|STD:0.002\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors-similarity|AVG:0.995|MIN:0.991|MAX:0.999|STD:0.003\n",
      "adamic_adar-common_neighbors-preferential_attachment-total_neighbors|AVG:0.995|MIN:0.991|MAX:1.000|STD:0.003\n",
      "adamic_adar|AVG:0.994|MIN:0.989|MAX:1.000|STD:0.004\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "statistics = evaluate_datasets(decision_tree)\n",
    "\n",
    "print_statistics(statistics, 'accuracy')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'precision')\n",
    "print('#'*10)\n",
    "print_statistics(statistics, 'recall')\n",
    "print('#'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
